<!doctype html><html lang=en>
<head>
<meta charset=utf-8>
<meta name=viewport content="width=device-width,initial-scale=1">
<meta name=robots content="noodp">
<meta http-equiv=x-ua-compatible content="IE=edge, chrome=1">
<title>신경망(Neural Network)과 활성화 함수(Activation Function) - </title><meta name=Description content="About LoveIt Theme"><meta property="og:title" content="신경망(Neural Network)과 활성화 함수(Activation Function)">
<meta property="og:description" content="Neural Network 신경망(Neural Net)은 퍼셉트론을 쌓아올려 알아서 파라미터를 결정할 수 있도록 만든 장치입니다.
신경망의 구조는 아래 그림과 같습니다.
이미지 출처 : kdnuggets.com
아래는 2개의 입력값 $(x_1, x_2)$을 받는 퍼셉트론을 수식으로 나타낸 것입니다. $(w_1, w_2)$는 각 입력값에 곱해지는 가중치이며 $b$ 는 편향(bias)입니다.
$$ y = \begin{cases} 0 \qquad (b + w_1x_1 + w_2x_2 \leq 0) 1 \qquad (b + w_1x_1 + w_2x_2 > 0) \end{cases} $$
위 식을 퍼셉트론의 결과를 나타내는 함수 $h(x)$를 사용하면 아래와 같이 나타낼 수 있습니다.">
<meta property="og:type" content="article">
<meta property="og:url" content="https://youngeun-in.github.io/%EC%8B%A0%EA%B2%BD%EB%A7%9D%EA%B3%BC-%ED%99%9C%EC%84%B1%ED%99%94%ED%95%A8%EC%88%98/"><meta property="og:image" content="https://youngeun-in.github.io/logo.png"><meta property="article:section" content="posts">
<meta property="article:published_time" content="2022-01-11T15:12:26+09:00">
<meta property="article:modified_time" content="2022-01-11T15:12:26+09:00">
<meta name=twitter:card content="summary_large_image">
<meta name=twitter:image content="https://youngeun-in.github.io/logo.png">
<meta name=twitter:title content="신경망(Neural Network)과 활성화 함수(Activation Function)">
<meta name=twitter:description content="Neural Network 신경망(Neural Net)은 퍼셉트론을 쌓아올려 알아서 파라미터를 결정할 수 있도록 만든 장치입니다.
신경망의 구조는 아래 그림과 같습니다.
이미지 출처 : kdnuggets.com
아래는 2개의 입력값 $(x_1, x_2)$을 받는 퍼셉트론을 수식으로 나타낸 것입니다. $(w_1, w_2)$는 각 입력값에 곱해지는 가중치이며 $b$ 는 편향(bias)입니다.
$$ y = \begin{cases} 0 \qquad (b + w_1x_1 + w_2x_2 \leq 0) 1 \qquad (b + w_1x_1 + w_2x_2 > 0) \end{cases} $$
위 식을 퍼셉트론의 결과를 나타내는 함수 $h(x)$를 사용하면 아래와 같이 나타낼 수 있습니다.">
<meta name=application-name content="DevLog">
<meta name=apple-mobile-web-app-title content="DevLog"><meta name=theme-color content="#ffffff"><meta name=msapplication-TileColor content="#da532c"><link rel="shortcut icon" type=image/x-icon href=/favicon.ico>
<link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png>
<link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5><link rel=manifest href=/site.webmanifest><link rel=canonical href=https://youngeun-in.github.io/%EC%8B%A0%EA%B2%BD%EB%A7%9D%EA%B3%BC-%ED%99%9C%EC%84%B1%ED%99%94%ED%95%A8%EC%88%98/><link rel=prev href=https://youngeun-in.github.io/spring-mocking-%EC%97%86%EC%9D%B4-%ED%85%8C%EC%8A%A4%ED%8A%B8%ED%95%98%EB%8A%94%EB%B2%95/><link rel=next href=https://youngeun-in.github.io/enum-usage-1/><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/normalize.css@8.0.1/normalize.min.css><link rel=stylesheet href=/css/style.min.css><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.13.0/css/all.min.css><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/animate.css@3.7.2/animate.min.css><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","headline":"신경망(Neural Network)과 활성화 함수(Activation Function)","inLanguage":"en","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/youngeun-in.github.io\/%EC%8B%A0%EA%B2%BD%EB%A7%9D%EA%B3%BC-%ED%99%9C%EC%84%B1%ED%99%94%ED%95%A8%EC%88%98\/"},"image":["https:\/\/youngeun-in.github.io\/images\/Apple-Devices-Preview.png"],"genre":"posts","keywords":"neural-net, sigmoid, relu","wordcount":1105,"url":"https:\/\/youngeun-in.github.io\/%EC%8B%A0%EA%B2%BD%EB%A7%9D%EA%B3%BC-%ED%99%9C%EC%84%B1%ED%99%94%ED%95%A8%EC%88%98\/","datePublished":"2022-01-11T15:12:26+09:00","dateModified":"2022-01-11T15:12:26+09:00","license":"This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.","publisher":{"@type":"Organization","name":"yyoungeunin","logo":"https:\/\/youngeun-in.github.io\/images\/avatar.png"},"author":{"@type":"Person","name":"yyoungeunin"},"description":""}</script><style>.search{position:relative;padding-top:3.5rem;padding-bottom:1rem;width:57.5%;margin:0 auto;background:#fff;opacity:.95}[theme=dark] .search{background:#3a3535}[theme=dark] .search header,.search header{background-color:#f8f8f8}[theme=dark] .search header:hover,.search header:hover{-webkit-box-shadow:none;box-shadow:none}.search header h1{padding-left:1rem;background:#fff}[theme=dark] .search header h1{background:#3a3535}[theme=dark] .search input,.search input{height:initial;width:initial;color:initial;background-color:#fff;margin:0 0 0 1rem;border-width:2px;border-style:inset;border-color:initial;border-image:initial;-webkit-border-radius:0;-moz-border-radius:0;border-radius:0}.search #search-results{padding-left:1rem;padding-right:1rem}[theme=dark] a:active,[theme=dark] a:hover{color:#2d96bd}.search hr{margin-left:1rem;margin-right:1rem}}</style>
</head>
<body header-desktop=fixed header-mobile=auto><script type=text/javascript>(window.localStorage&&localStorage.getItem('theme')?localStorage.getItem('theme')==='dark':'auto'==='auto'?window.matchMedia('(prefers-color-scheme: dark)').matches:'auto'==='dark')&&document.body.setAttribute('theme','dark')</script>
<div id=mask></div><div class=wrapper><header class=desktop id=header-desktop>
<div class=header-wrapper>
<div class=header-title>
<a href=/ title><span id=id-1 class=typeit></span></a>
</div>
<div class=menu>
<div class=menu-inner><a class=menu-item href=/posts/> Posts </a><a class=menu-item href=/categories/> Categories </a><a class=menu-item href=/tags/> Tags </a><a class=menu-item href=/search/><i class="fas fa-fw fa-search"></i> Search </a><a class=menu-item href=/about/> About </a><a class=menu-item href=https://github.com/YouneEun-IN title=GitHub rel="noopener noreffer" target=_blank><i class="fab fa-github fa-fw"></i> </a><span class="menu-item delimiter"></span><a href=javascript:void(0); class="menu-item theme-switch" title="Switch Theme">
<i class="fas fa-adjust fa-fw"></i>
</a>
</div>
</div>
</div>
</header><header class=mobile id=header-mobile>
<div class=header-container>
<div class=header-wrapper>
<div class=header-title>
<a href=/ title><span id=id-2 class=typeit></span></a>
</div>
<div class=menu-toggle id=menu-toggle-mobile>
<span></span><span></span><span></span>
</div>
</div>
<div class=menu id=menu-mobile><a class=menu-item href=/posts/ title>Posts</a><a class=menu-item href=/categories/ title>Categories</a><a class=menu-item href=/tags/ title>Tags</a><a class=menu-item href=/search/ title><i class="fas fa-fw fa-search"></i>Search</a><a class=menu-item href=/about/ title>About</a><a class=menu-item href=https://github.com/YouneEun-IN title=GitHub rel="noopener noreffer" target=_blank><i class="fab fa-github fa-fw"></i></a><a href=javascript:void(0); class="menu-item theme-switch" title="Switch Theme">
<i class="fas fa-adjust fa-fw"></i>
</a></div>
</div>
</header>
<div class="search-dropdown desktop">
<div id=search-dropdown-desktop></div>
</div>
<div class="search-dropdown mobile">
<div id=search-dropdown-mobile></div>
</div>
<main class=main>
<div class=container>
<div class=toc id=toc-auto>
<h2 class=toc-title>Contents</h2>
<div class=toc-content id=toc-content-auto></div>
</div><article class="page single"><h1 class="single-title animated flipInX">신경망(Neural Network)과 활성화 함수(Activation Function)</h1><div class=post-meta>
<div class=post-meta-line><span class=post-author><a href=/ title=Author rel=author class=author><i class="fas fa-user-circle fa-fw"></i>yyoungeunin</a></span>&nbsp;<span class=post-category>included in <a href=/categories/ml/><i class="far fa-folder fa-fw"></i>ML</a></span></div>
<div class=post-meta-line><i class="far fa-calendar-alt fa-fw"></i>&nbsp;<time datetime=2022-01-11>2022-01-11</time>&nbsp;<i class="fas fa-pencil-alt fa-fw"></i>&nbsp;1105 words&nbsp;
<i class="far fa-clock fa-fw"></i>&nbsp;6 minutes&nbsp;</div>
</div><div class="details toc" id=toc-static kept>
<div class="details-summary toc-title">
<span>Contents</span>
<span><i class="details-icon fas fa-angle-right"></i></span>
</div>
<div class="details-content toc-content" id=toc-content-static><nav id=TableOfContents>
<ul>
<li><a href=#neural-network>Neural Network</a></li>
<li><a href=#activation-function>Activation Function</a>
<ul>
<li><a href=#step-function>Step Function</a></li>
<li><a href=#sigmoid-function>Sigmoid Function</a></li>
<li><a href=#relu-function>ReLU Function</a></li>
<li><a href=#softmax>Softmax</a></li>
</ul>
</li>
</ul>
</nav></div>
</div><div class=content id=content><h2 id=neural-network>Neural Network</h2>
<p>신경망(Neural Net)은 퍼셉트론을 쌓아올려 알아서 파라미터를 결정할 수 있도록 만든 장치입니다.</p>
<p>신경망의 구조는 아래 그림과 같습니다.</p>
<p align=center><img src=https://i.imgur.com/McMOhuQ.png alt=NeuralNet style=zoom:80%></p>
<p align=center style=font-size:80%>이미지 출처 : <a href=https://www.kdnuggets.com/2017/10/neural-network-foundations-explained-gradient-descent.html>kdnuggets.com</a></p>
<p>아래는 2개의 입력값 $(x_1, x_2)$을 받는 퍼셉트론을 수식으로 나타낸 것입니다. $(w_1, w_2)$는 각 입력값에 곱해지는 가중치이며 $b$ 는 편향(bias)입니다.</p>
<p>$$
y = \begin{cases} 0 \qquad (b + w_1x_1 + w_2x_2 \leq 0)
1 \qquad (b + w_1x_1 + w_2x_2 > 0) \end{cases}
$$</p>
<p>위 식을 퍼셉트론의 결과를 나타내는 함수 $h(x)$를 사용하면 아래와 같이 나타낼 수 있습니다.</p>
<p>$$
y = h(b + w_1x_1 + w_2x_2)
h(x) = \begin{cases} 0 \qquad (x \leq 0)
1 \qquad (x > 0) \end{cases}
$$</p>
<p>여기서 $h(x)$는 **활성화 함수(Activation function)**라고 합니다. 활성화 함수는 가중치가 곱해진 신호의 총합이 활성화를 일으키는지, 즉 임곗값을 넘는지를 판단하게 됩니다. 임계값을 넘으면 $1$ 을, 그보다 작으면 $0$ 을 나타내게 되지요. 아래는 이 과정을 나타낸 것입니다.</p>
<p align=center><img src=https://www.i2tutorials.com/wp-content/media/2019/09/Deep-learning-20-i2tutorials.png alt="activation f" style=zoom:80%></p>
<p align=center style=font-size:80%>이미지 출처 : <a href=https://www.i2tutorials.com/explain-activation-function-in-neural-network-and-its-types/>i2tutorials.com</a></p>
<h2 id=activation-function>Activation Function</h2>
<p>그렇다면 활성화 함수는 어떤 것들이 있고 왜 이렇게 생기게 되었는 지에 대해서 조금 더 자세히 알아보겠습니다.</p>
<h3 id=step-function>Step Function</h3>
<p>활성화 함수는 신경망의 행동을 결정하는 중요한 역할을 합니다. 가장 간단한 형태의 활성화 함수는 **계단 함수(Step function)**라고 합니다. 계단 함수는 위에서 살펴본 $h(x)$ 와 같이 행동합니다. 입력값의 합이 임계값을 넘으면 $0$ 을, 넘지 못하면 $1$ 을 출력하게 됩니다. 이에 따른 계단 함수의 그래프는 다음과 같이 생겼습니다.</p>
<p align=center><img src=https://upload.wikimedia.org/wikipedia/commons/thumb/d/d9/Dirac_distribution_CDF.svg/1280px-Dirac_distribution_CDF.svg.png alt=step_function style=zoom:33%></p>
<p align=center style=font-size:80%>이미지 출처 : <a href=https://en.wikipedia.org/wiki/Heaviside_step_function>wikipedia - Heaviside step function</a></p>
<p>계단 함수는 활성화 함수의 조건을 가장 잘 만족하는 함수이고 직관적으로도 이해하기 쉽습니다. 하지만 두 가지 단점 때문에 실제 신경망에 사용되지는 않습니다. 첫 번째 단점은 **불연속(Discontinuous)**입니다. 그래프를 보면 알 수 있듯 임계값 지점에서 불연속점을 갖게 되는데 이 점에서 미분이 불가능하기 때문에 학습이 필요한 신경망에 사용할 수 없습니다. 두 번째 단점은 <strong>다른 지점에서 미분값이 $0$이 된다</strong>는 점입니다. 추후 역전파 과정에서 미분값을 통해 학습을 하게 되는데 이 값이 0이 되어버리면 제대로 된 학습이 안되지요. 이런 문제점을 해결하기 위해서 등장한 것이 **시그모이드 함수(Sigmoid)**입니다.</p>
<h3 id=sigmoid-function>Sigmoid Function</h3>
<p>시그모이드 함수는 기본적으로 $S$ 모양을 그리는 곡선 함수를 통칭하여 부르는 말입니다. 이 중 대표적인 함수는 <strong>로지스틱(Logistic) 함수</strong>와 <strong>하이퍼탄젠트(Hyper tangent, $\tanh$) 함수</strong>가 있습니다. 두 함수의 수식과 그래프를 보며 시그모이드 함수와 계단 함수가 다른 점이 무엇인지 알아보도록 하겠습니다.</p>
<p><strong>로지스틱 함수(Logistic Function)</strong></p>
<p>$$
\text{Logistic} : \frac{1}{1+e^{-x}}
$$</p>
<p align=center><img src=https://upload.wikimedia.org/wikipedia/commons/thumb/8/88/Logistic-curve.svg/1920px-Logistic-curve.svg.png alt=logistic style=zoom:25%></p>
<p align=center style=font-size:80%>이미지 출처 : <a href=https://en.wikipedia.org/wiki/Logistic_function>wikipedia - Logistic function</a></p>
<p><strong>하이퍼탄젠트 함수(Hypertangent Function)</strong></p>
<p>$$
\text{Hypertangent} : \frac{e^x-e^{-x}}{e^x+e^{-x}} = \frac{e^{2x}-1}{e^{2x}+1}
$$</p>
<p align=center><img src=https://mathworld.wolfram.com/images/interactive/TanhReal.gif alt=hyper style=zoom:110%></p>
<p align=center style=font-size:80%>이미지 출처 : <a href=https://mathworld.wolfram.com/HyperbolicTangent.html>mathworld.wolfram.com</a></p>
<p>두 함수는 모두 연속함수입니다. 계단 함수의 치명적인 단점이었던 불연속을 해결했지요. 계단 함수와 시그모이드 함수의 중요한 공통점은 **비선형 함수(Non-linear)**라는 점입니다.</p>
<p>활성화 함수는 비선형 함수를 사용해야 합니다. 활성화 함수가 선형 함수이면 안되는 이유는 무엇일까요? 선형인 활성화 함수 $l(x) = ax + b$ 가 있다고 해보겠습니다. 이 함수를 사용하여 3개의 층을 쌓는다면 최종적인 활성화 함수는 $l(l(l(x))) = l^3(x) = a(a(ax+b)+b)+b = a^3x+a^2b+ab+b$가 됩니다. $a^3 = c, d = a^2b+ab+b$라고 하면 $l^3(x) = cx+d$로 여전히 같은 형태의 함수를 사용하게 됩니다. 층을 아무리 깊게 쌓아도 여러 층을 쌓는 이점을 살리지 못하게 되지요. 여러 층을 쌓을 때의 장점을 살리기 위해 비선형 함수를 사용하게 되는 것이지요.</p>
<h3 id=relu-function>ReLU Function</h3>
<p>시그모이드 함수는 불연속이라는 계단 함수의 한 가지 단점을 해결했습니다. 하지만 나머지 단점 하나는 해결하지 못했습니다. 시그모이드도 여전히 대부분의 점에서 기울기 값이 0이 되지요. 이 때문에 **기울기 소실(Gradient vanishing)**이라는 문제가 발생합니다. 기울기 소실은 시그모이드 함수를 활성화 함수로 사용하여 층을 깊게 쌓았을 때 <strong>학습이 잘 되지 않는 현상</strong>입니다. 이런 현상이 왜 발생하는지 알아보겠습니다.</p>
<p>로지스틱 함수 $L(x)$를 미분한 함수 $L^\prime(x)$ 의 수식은 다음과 같습니다.</p>
<p>$$
L^\prime(x) = \bigg(\frac{1}{1+e^{-x}}\bigg)^\prime = \frac{e^x}{(1+e^{-x})^2}
$$</p>
<p>위 함수의 그래프는 아래와 같이 생겼습니다.</p>
<p align=center><img src=https://user-images.githubusercontent.com/45377884/91560184-5d5bd900-e974-11ea-8c02-2a182c6a7c93.png alt=logistic_deri style=zoom:67%></p>
<p>그래프에서 볼 수 있듯 최댓값이 $0.25$ 밖에 되지 않고 $x&lt;-5, x>5$ 범위에서는 거의 $0$ 에 가깝습니다. <a href=https://yngie-c.github.io/deep%20learning/2020/03/14/back_propagation/ target=_blank rel="noopener noreffer">역전파(Back propagation)</a> 과정에서는 미분값을 사용하여 학습을 하게 됩니다. 따라서 이 값이 0에 가까워 지면 정보가 유실되면서 학습이 잘 안되게 됩니다. 특히 층을 깊게 쌓을 경우에는 정보가 모두 유실되는 사태가 발생하게 되지요.</p>
<p>그렇다면 하이퍼탄젠트 함수는 어떻게 될까요? 하이퍼탄젠트 함수 $\tanh$를 미분한 함수의 수식은 다음과 같습니다.</p>
<p>$$
\tanh^\prime(x) = \bigg(\frac{e^x-e^{-x}}{e^x+e^{-x}}\bigg)^\prime = \frac{4e^{2x}}{(1+e^{2x})^2}
$$</p>
<p>위 함수의 그래프는 아래와 같이 생겼습니다.</p>
<p align=center><img src=https://user-images.githubusercontent.com/45377884/91560164-52a14400-e974-11ea-8bf4-bbfc7fd42deb.png alt=hypertangent_deri style=zoom:67%></p>
<p>하이퍼탄젠트 함수를 미분한 함수의 최댓값은 $1$ 입니다. 최댓값이 $0.25$ 밖에 안되었던 로지스틱 함수 보다는 정보를 잘 전달하게 되지요. 하지만 여전히 $x$ 가 0에서 멀어질수록 원래 함수의 미분값은 0에 가까워집니다. 그래서 하이퍼탄젠트 함수를 활성화 함수로 하더라도 퍼셉트론을 여러 층으로 쌓는다면 학습이 제대로 안되게 되지요. 이렇게 시그모이드 함수를 활성화 함수로 사용할 때 역전파시 학습이 제대로 진행되지 않는 현상을 <strong>기울기 소실</strong>이라고 합니다.</p>
<p>기울기 소실 문제를 극복하기 위해서 등장한 함수가 바로 <strong>ReLU(Rectified Linear Unit)함수</strong>입니다. ReLU함수는 입력값이 0보다 작을 경우에는 0을 반환하고, 0보다 클 경우에는 입력값을 그대로 반환합니다. 아래는 ReLU함수를 수식으로 나타낸 것입니다.
$$
h(x) = \begin{cases} 0 \qquad (x \leq 0) \
x \qquad (x > 0) \end{cases}
$$</p>
<p>아래는 ReLU함수의 그래프를 나타낸 것입니다.</p>
<p align=center><img src=https://miro.medium.com/max/1225/0*g9ypL5M3k-f7EW85.png alt=ReLU style=zoom:50%></p>
<p align=center style=font-size:80%>이미지 출처 : <a href=https://medium.com/@sonish.sivarajkumar/relu-most-popular-activation-function-for-deep-neural-networks-10160af37dda>medium.com</a></p>
<p>ReLU함수는 $x$ 가 $0$ 보다 클 때, 미분값이 항상 $1$ 입니다. 그래서 층이 아무리 깊어져도 손실없이 정보를 전달할 수 있습니다. 미분값이 항상 $0$과 $1$ 이기 때문에 연산이 빠르다는 점도 ReLU함수의 장점입니다. 덕분에 ReLU함수는 은닉층에서 가장 많이 사용되는 활성화 함수가 되었습니다. 물론 ReLU함수에게도 문제가 있습니다. 0이하의 값이 그대로 보존되지 않고 버려진다는 것이지요. 이를 보완하기 위해 <strong>Leaky ReLU</strong>함수가 고안되어 사용되고 있습니다. Leaky ReLU 함수 $h_\text{Leaky}(x)$의 수식은 다음과 같습니다.</p>
<p>$$
h_\text{Leaky}(x) = \begin{cases} ax \qquad (x \leq 0) \
x \qquad (x > 0) \end{cases}
$$</p>
<p>일반적으로는 $a=0.01$을 사용하며 그래프는 다음과 같습니다.</p>
<p align=center><img src=https://miro.medium.com/max/1225/1*siH_yCvYJ9rqWSUYeDBiRA.png alt=leaky style=zoom:50%></p>
<p align=center style=font-size:80%>이미지 출처 : <a href=https://medium.com/@himanshuxd/activation-functions-sigmoid-relu-leaky-relu-and-softmax-basics-for-neural-networks-and-deep-8d9c70eed91e>medium.com</a></p>
<h3 id=softmax>Softmax</h3>
<p>은닉층(Hidden Layer)의 활성화 함수로는 일반적으로 ReLU함수 혹은 Leaky ReLU와 같은 ReLU함수를 변형한 함수가 주로 사용됩니다. 하지만 출력층의 활성화 함수는 우리가 하고자 하는 작업에 맞게 조정해주어야 합니다. 일반적으로 회귀( Regression), 즉 연속형 변수에 대한 예측값을 출력하는 경우에는 출력층의 활성화 함수로 항등함수 $h_\text{reg}(x) = x$ 를 사용합니다.</p>
<p>이진 분류의 경우에는 입력값을 받아 $0$ 혹은 $1$ 의 값을 출력하는 것이므로 주로 로지스틱 함수를 많이 사용합니다. 그렇다면 인스턴스를 다중 레이블로 분류하는 경우에는 어떤 활성화 함수를 사용하는 것이 좋을까요? 이런 질문에 대한 답으로 나온 것이 바로 <strong>소프트맥스(Softmax) 함수</strong>입니다. 소프트맥스 함수는 이진 분류에서 사용하는 로지스틱 함수를 다중 분류에서 사용할 수 있도록 일반화한 함수입니다. 소프트맥스의 함수는 다음과 같습니다.</p>
<p>$$
y_k = \frac{\exp(a_k)}{\sum^n_{i=1}\exp(a_i)}
$$</p>
<p>소프트맥스도 함수도 사용할 때 주의해야 할 점이 있습니다. 소프트맥스 함수가 지수함수이기 때문에 $a$ 값이 커지게 되면 $\exp(a)$ 값이 매우 커지게 됩니다. <code>__int32</code>가 최대로 나타낼 수 있는 숫자는 $2,147,483,647$ 인데 $a = 22$ 만 되더라도 표현할 수 있는 값 이상이 되어 오버플로(Overflow)현상이 발생합니다. 또한 부동소수점 표기 특성상, 작은 숫자를 큰 값으로 나누면 수치가 불안정해지는 문제 역시 발생하게 됩니다.</p>
<p>이런 문제를 해결하기 위해서 실제로 소프트맥스 함수를 사용하기 위해서는 상수 $C$를 곱해주어 스케일을 조정해주는 과정이 필요합니다. 실제로 구현되어 있는 소프트맥스 함수의 수식은 아래와 같습니다.</p>
<p>$$
\begin{aligned}
y_k &= \frac{\exp(a_k)}{\sum^n_{i=1}\exp(a_i)} = \frac{C\exp(a_k)}{C\sum^n_{i=1}\exp(a_i)} <br>
&= \frac{\exp(a_k +\log C)}{\sum^n_{i=1}\exp(a_i + \log C)} <br>
&= \frac{\exp(a_k +C^\prime)}{\sum^n_{i=1}\exp(a_i + C^\prime)}
\end{aligned}
$$</p>
<p>위 식에서 $C^\prime = \log C$로, $C^\prime$에는 0보다 작은 값이면 어떤 값을 대입하든 상관 없지만 오버플로를 막기 위해서 일반적으로 $a_i {i=1, \cdots ,n}$ 중 가장 큰 값에 $-1$ 을 곱해준 값을 사용합니다. 예를 들어, $a_i = [1000, 1050, 1100]$이면 $C^\prime = -1100$ 이 됩니다.</p>
<p>소프트맥스 함수의 출력값은 항상 $[0,1]$ 범위 내에 있으며 모든 출력값을 더한 값이 1이 된다는, 즉 $\sum^n_{i=1}y_i = 1$ 이라는 특징이 있습니다. 이런 성질 덕분에 소프트맥스의 출력값을 확률(Probability)로도 해석할 수 있습니다. 다중 레이블에 대한 확률이 필요한 경우 소프트맥스 함수를 사용합니다.</p>
</div><div class=post-footer id=post-footer>
<div class=post-info>
<div class=post-info-line>
<div class=post-info-mod>
<span>Updated on 2022-01-11</span>
</div>
<div class=post-info-license></div>
</div>
<div class=post-info-line>
<div class=post-info-md><span>
<a class=link-to-markdown href=/%EC%8B%A0%EA%B2%BD%EB%A7%9D%EA%B3%BC-%ED%99%9C%EC%84%B1%ED%99%94%ED%95%A8%EC%88%98/index.md target=_blank>Read Markdown</a>
</span></div>
<div class=post-info-share>
<span><a href=javascript:void(0); title="Share on Twitter" data-sharer=twitter data-url=https://youngeun-in.github.io/%EC%8B%A0%EA%B2%BD%EB%A7%9D%EA%B3%BC-%ED%99%9C%EC%84%B1%ED%99%94%ED%95%A8%EC%88%98/ data-title="신경망(Neural Network)과 활성화 함수(Activation Function)" data-hashtags=neural-net,sigmoid,relu><i class="fab fa-twitter fa-fw"></i></a><a href=javascript:void(0); title="Share on Facebook" data-sharer=facebook data-url=https://youngeun-in.github.io/%EC%8B%A0%EA%B2%BD%EB%A7%9D%EA%B3%BC-%ED%99%9C%EC%84%B1%ED%99%94%ED%95%A8%EC%88%98/ data-hashtag=neural-net><i class="fab fa-facebook-square fa-fw"></i></a><a href=javascript:void(0); title="Share on Hacker News" data-sharer=hackernews data-url=https://youngeun-in.github.io/%EC%8B%A0%EA%B2%BD%EB%A7%9D%EA%B3%BC-%ED%99%9C%EC%84%B1%ED%99%94%ED%95%A8%EC%88%98/ data-title="신경망(Neural Network)과 활성화 함수(Activation Function)"><i class="fab fa-hacker-news fa-fw"></i></a><a href=javascript:void(0); title="Share on Line" data-sharer=line data-url=https://youngeun-in.github.io/%EC%8B%A0%EA%B2%BD%EB%A7%9D%EA%B3%BC-%ED%99%9C%EC%84%B1%ED%99%94%ED%95%A8%EC%88%98/ data-title="신경망(Neural Network)과 활성화 함수(Activation Function)"><i data-svg-src=https://cdn.jsdelivr.net/npm/simple-icons@2.14.0/icons/line.svg></i></a><a href=javascript:void(0); title="Share on 微博" data-sharer=weibo data-url=https://youngeun-in.github.io/%EC%8B%A0%EA%B2%BD%EB%A7%9D%EA%B3%BC-%ED%99%9C%EC%84%B1%ED%99%94%ED%95%A8%EC%88%98/ data-title="신경망(Neural Network)과 활성화 함수(Activation Function)"><i class="fab fa-weibo fa-fw"></i></a></span>
</div>
</div>
</div>
<div class=post-info-more>
<section class=post-tags><i class="fas fa-tags fa-fw"></i>&nbsp;<a href=/tags/neural-net/>neural-net</a>,&nbsp;<a href=/tags/sigmoid/>sigmoid</a>,&nbsp;<a href=/tags/relu/>relu</a></section>
<section>
<span><a href=javascript:void(0); onclick=window.history.back()>Back</a></span>&nbsp;|&nbsp;<span><a href=/>Home</a></span>
</section>
</div>
<div class=post-nav><a href=/spring-mocking-%EC%97%86%EC%9D%B4-%ED%85%8C%EC%8A%A4%ED%8A%B8%ED%95%98%EB%8A%94%EB%B2%95/ class=prev rel=prev title="Spring mocking 없이 테스트하는법"><i class="fas fa-angle-left fa-fw"></i>Spring mocking 없이 테스트하는법</a>
<a href=/enum-usage-1/ class=next rel=next title="Enum 사용 (개념)">Enum 사용 (개념)<i class="fas fa-angle-right fa-fw"></i></a></div>
</div>
<div id=comments><div id=utterances></div><noscript>
Please enable JavaScript to view the comments powered by <a href=https://utteranc.es/>Utterances</a>.
</noscript></div></article></div>
</main><footer class=footer>
<div class=footer-container><div class=footer-line>Powered by <a href=https://gohugo.io/ target=_blank rel="noopener noreffer" title="Hugo 0.92.0">Hugo</a> | Theme - <a href=https://github.com/dillonzq/LoveIt target=_blank rel="noopener noreffer" title="LoveIt 0.2.10"><i class="far fa-kiss-wink-heart fa-fw"></i> LoveIt</a>
</div><div class=footer-line><i class="far fa-copyright fa-fw"></i><span itemprop=copyrightYear>2019 - 2022</span><span class=author itemprop=copyrightHolder>&nbsp;<a href=/ target=_blank>yyoungeunin</a></span>&nbsp;|&nbsp;<span class=license><a rel="license external nofollow noopener noreffer" href=https://creativecommons.org/licenses/by-nc/4.0/ target=_blank>CC BY-NC 4.0</a></span></div>
</div>
</footer>
</div>
<div id=fixed-buttons><a href=# id=back-to-top class=fixed-button title="Back to Top">
<i class="fas fa-arrow-up fa-fw"></i>
</a><a href=# id=view-comments class=fixed-button title="View Comments">
<i class="fas fa-comment fa-fw"></i>
</a>
</div><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/copy-tex.min.css><script type=text/javascript src=https://cdn.jsdelivr.net/npm/smooth-scroll@16.1.3/dist/smooth-scroll.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/lazysizes@5.2.2/lazysizes.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/clipboard@2.0.6/dist/clipboard.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/sharer.js@0.4.0/sharer.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/typeit@7.0.4/dist/typeit.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/copy-tex.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/mhchem.min.js></script><script type=text/javascript>window.config={code:{copyTitle:"Copy to clipboard",maxShownLines:-1},comment:{utterances:{darkTheme:"github-dark",issueTerm:"pathname",label:"",lightTheme:"github-light",repo:"YoungEun-IN/blog-comment"}},data:{"id-1":"DevLog","id-2":"DevLog"},math:{delimiters:[{display:!0,left:"$$",right:"$$"},{display:!0,left:"\\[",right:"\\]"},{display:!1,left:"$",right:"$"},{display:!1,left:"\\(",right:"\\)"}],strict:!1},typeit:{cursorChar:"|",cursorSpeed:1e3,data:{"id-1":["id-1"],"id-2":["id-2"]},duration:-1,speed:100}}</script><script type=text/javascript src=/js/theme.min.js></script></body>
</html>