<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title>step-function - Tag -</title><link>https://youngeun-in.github.io/tags/step-function/</link><description>step-function - Tag -</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright><lastBuildDate>Tue, 11 Jan 2022 15:12:26 +0900</lastBuildDate><atom:link href="https://youngeun-in.github.io/tags/step-function/" rel="self" type="application/rss+xml"/><item><title>활성화 함수</title><link>https://youngeun-in.github.io/%ED%99%9C%EC%84%B1%ED%99%94-%ED%95%A8%EC%88%98/</link><pubDate>Tue, 11 Jan 2022 15:12:26 +0900</pubDate><author>Author</author><guid>https://youngeun-in.github.io/%ED%99%9C%EC%84%B1%ED%99%94-%ED%95%A8%EC%88%98/</guid><description>Step Function 활성화 함수는 신경망의 행동을 결정하는 중요한 역할을 합니다. 가장 간단한 형태의 활성화 함수는 계단 함수(Step function) 라고 합니다. 계단 함수는 입력값의 합이 임계값을 넘으면 $0$ 을, 넘지 못하면 $1$ 을 출력하게 됩니다. 계단 함수의 그래프는 다음과 같이 생겼습니다.
이미지 출처 : wikipedia - Heaviside step function
계단 함수는 활성화 함수의 조건을 가장 잘 만족하는 함수이고 직관적으로도 이해하기 쉽습니다. 하지만 불연속 함수라는 단점 때문에 실제 신경망에 사용되지는 않습니다. 그래프를 보면 알 수 있듯 임계값 지점에서 불연속점을 갖게 되는데 이 점에서 미분이 불가능하기 때문에 학습이 필요한 신경망에 사용할 수 없습니다.</description></item></channel></rss>