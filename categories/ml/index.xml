<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title>ML - Category -</title><link>https://youngeun-in.github.io/categories/ml/</link><description>ML - Category -</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright><lastBuildDate>Sun, 27 Mar 2022 15:12:26 +0900</lastBuildDate><atom:link href="https://youngeun-in.github.io/categories/ml/" rel="self" type="application/rss+xml"/><item><title>선형회귀</title><link>https://youngeun-in.github.io/%EC%84%A0%ED%98%95%ED%9A%8C%EA%B7%80/</link><pubDate>Sun, 27 Mar 2022 15:12:26 +0900</pubDate><author>Author</author><guid>https://youngeun-in.github.io/%EC%84%A0%ED%98%95%ED%9A%8C%EA%B7%80/</guid><description>선형 회귀는 한 개 이상의 독립 변수 x와 y의 선형 관계를 모델링한다.
가중치 행렬을 W, 편향을 b, 실제값을 y라고 할 때, 선형회귀는 비용함수 MSE를 최소화하는 W와 b를 추정해 나가는 과정이다.
계산 과정 편차를 $WX_{i}+b-y_{i}$라고 할 때, 비용함수는 다음과 같다.
$$\sum_{i=1}^{m} (WX_{i}+b-y_{i})^2 = \sum_{i=1}^{m}(X_{i}^2W^2+2X_{i}bW-2by_{i}-2X_{i}y_{i}W+b^2+yi^2)$$
비용함수를 W로 각각 편미분 하면 다음과 같다.
$$\partial{W} = \cfrac{\partial{cost(W,b)}} {\partial{W}} = \sum_{i=1}^{m}(2X_{i}^2W+2X_{i}b-2X_{i}y_{i})\cdot \cfrac{1}{m} $$
$$= 2X_{i}\sum_{i=1}^{m} (WX_{i}+b-y_{i})\cdot \cfrac{1}{m}$$
비용함수를 b로 각각 편미분 하면 다음과 같다.
$$\partial{b} = \cfrac{\partial{cost(W,b)}} {\partial{b}} = \sum_{i=1}^{m}(2X_{i}W-2y_{i}+2b)\cdot \cfrac{1}{m}$$</description></item><item><title>활성화 함수</title><link>https://youngeun-in.github.io/%ED%99%9C%EC%84%B1%ED%99%94-%ED%95%A8%EC%88%98/</link><pubDate>Tue, 11 Jan 2022 15:12:26 +0900</pubDate><author>Author</author><guid>https://youngeun-in.github.io/%ED%99%9C%EC%84%B1%ED%99%94-%ED%95%A8%EC%88%98/</guid><description>Step Function 활성화 함수는 신경망의 행동을 결정하는 중요한 역할을 합니다. 가장 간단한 형태의 활성화 함수는 계단 함수(Step function) 라고 합니다. 계단 함수는 입력값의 합이 임계값을 넘으면 $0$ 을, 넘지 못하면 $1$ 을 출력하게 됩니다. 계단 함수의 그래프는 다음과 같이 생겼습니다.
이미지 출처 : wikipedia - Heaviside step function
계단 함수는 활성화 함수의 조건을 가장 잘 만족하는 함수이고 직관적으로도 이해하기 쉽습니다. 하지만 불연속 함수라는 단점 때문에 실제 신경망에 사용되지는 않습니다. 그래프를 보면 알 수 있듯 임계값 지점에서 불연속점을 갖게 되는데 이 점에서 미분이 불가능하기 때문에 학습이 필요한 신경망에 사용할 수 없습니다.</description></item></channel></rss>